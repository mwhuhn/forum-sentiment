{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Topic Models\n",
    "Generates the topic models of forum posts with LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "## Data Sources\n",
    "- corpus (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "- dictionary (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "- lemmatized_text (created with 3.0-Topic_Models-Lemmatize_Text.ipynb)\n",
    "\n",
    "## Changes\n",
    "- 2020-09-16: Created\n",
    "- 2020-09-17: Found topic model with highest coherence and generated dominant topics\n",
    "- 2020-12-19: Added new data\n",
    "\n",
    "## TODO\n",
    "- Tutorial\n",
    " - https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    " - https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from io import FileIO\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "import pandas as pd\n",
    "from youbemom import create_connection\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mwh/miniconda3/envs/forum/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For formatting LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_coherence(fn, n_workers, n_topics, coherence, perplexity):\n",
    "    with open(fn, 'a') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow([n_workers, n_topics, coherence, perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sample(fn, n, coherence, perplexity):\n",
    "    with open(fn, 'a') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow([n, coherence, perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(fn, results):\n",
    "    with open(fn, 'a') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_topics(topics):\n",
    "    return [t[1] for t in topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(forum=\"special-needs\", group=\"parent\"):\n",
    "    lemmatized_text = pickle.load(open(path_lemma_pkl.format(forum, group), 'rb'))\n",
    "    corpus = pickle.load(open(path_corpus_pkl.format(forum, group), 'rb'))\n",
    "    dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(forum, group))\n",
    "    return lemmatized_text, corpus, dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to load\n",
    "path_lemma_pkl = str(path_parent / \"clean_data\" / \"lemmatized_text_{0}_{1}.pkl\")\n",
    "path_corpus_pkl = str(path_parent / \"clean_data\" / \"corpus_{0}_{1}.pkl\")\n",
    "path_dictionary_gensim = str(path_parent / \"clean_data\" / \"dictionary_{0}_{1}.gensim\")\n",
    "# model saving\n",
    "path_tune_models = str(path_parent / \"clean_data\" / \"lda_tune_{0}_{1}_{2}.gensim\")\n",
    "# save all tuning results\n",
    "path_a_b_t_tune = str(path_parent / \"clean_data\" / \"a_b_t_tune_{0}_{1}_{2}_{3}.csv\")\n",
    "path_resample = str(path_parent / \"clean_data\" / \"resample_10_topics_{0}_{1}.csv\")\n",
    "# path_coherence = str(path_parent / \"clean_data\" / \"coherence_{}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Needs: Parent Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text, corpus, dictionary = load_data('special-needs', 'parent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune LDA on grid search to optimize hyperparameters n_topics, alpha, and beta (eta). Saves all coherence scores computed but only saves best topic model for each number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forum = 'special-needs'\n",
    "group = 'parent'\n",
    "search = 'grid'\n",
    "run = \"2\"\n",
    "NUM_WORDS = 10\n",
    "n_iterations = 50\n",
    "w = 15 # 16 cores (1 main + 15 workers)\n",
    "a_list = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "b_list = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "best_models = {}\n",
    "for n_topics in range(4, 21):\n",
    "    model_name = \"topics_{}\".format(str(n_topics))\n",
    "    for a in a_list:\n",
    "        for b in b_list:\n",
    "            print(\"topics: {}, alpha: {}, beta: {}\".format(n_topics, a, b))\n",
    "            %time ldamodel = LdaMulticore(corpus, num_topics = n_topics, id2word=dictionary, passes=n_iterations, alpha=a, eta=b, workers=w)\n",
    "            topics = ldamodel.print_topics(num_words=NUM_WORDS)\n",
    "            perplexity = ldamodel.log_perplexity(corpus)\n",
    "            coherence_model = CoherenceModel(model=ldamodel, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "            coherence = coherence_model.get_coherence()\n",
    "            print(model_name)\n",
    "            print(best_models.keys())\n",
    "            if model_name not in best_models:\n",
    "                best_models[model_name] = {\"alpha\":a, \"beta\":b, \"coherence\":coherence}\n",
    "                ldamodel.save(path_tune_models.format(forum, group, str(n_topics)))\n",
    "            else:\n",
    "                print(best_models[model_name][\"coherence\"])\n",
    "                print(coherence)\n",
    "                if best_models[model_name][\"coherence\"] < coherence:\n",
    "                    print(\"new best model\")\n",
    "                    best_models[model_name] = {\"alpha\":a, \"beta\":b, \"coherence\":coherence}\n",
    "                    ldamodel.save(path_tune_models.format(forum, group, str(n_topics)))\n",
    "            for topic in topics:\n",
    "                write_list(path_a_b_t_tune.format(forum, group, search, run), [coherence, perplexity, n_topics, a, b, topic[0], topic[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forum = 'special-needs'\n",
    "group = 'parent'\n",
    "n_topics = 10\n",
    "a = 0.7\n",
    "b = 0.1\n",
    "NUM_WORDS = 10\n",
    "n_iterations = 50\n",
    "n_samples = 100\n",
    "w = 15 # 16 cores (1 main + 15 workers)\n",
    "for s in range(30, 101):\n",
    "    print(\"sample: {}\".format(s))\n",
    "    %time ldamodel = LdaMulticore(corpus, num_topics = n_topics, id2word=dictionary, passes=n_iterations, alpha=a, eta=b, workers=w)\n",
    "    topics = ldamodel.print_topics(num_words=NUM_WORDS)\n",
    "    coherence_model = CoherenceModel(model=ldamodel, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    for topic in topics:\n",
    "        write_list(path_resample.format(forum, group), [s, coherence, topic[0], topic[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the topics. See: https://www.objectorientedsubject.net/2018/08/experiments-on-topic-modeling-pyldavis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Needs: All Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text, corpus, dictionary = load_data('special-needs', 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum = 'special-needs'\n",
    "group = 'all'\n",
    "search = 'grid'\n",
    "run = \"1\"\n",
    "NUM_WORDS = 10\n",
    "n_iterations = 50\n",
    "w = 15 # 16 cores (1 main + 15 workers)\n",
    "a_list = [.1, .3, .5, .7, .9]\n",
    "b_list = [.1, .3, .5, .7, .9]\n",
    "best_models = {}\n",
    "for n_topics in range(7, 18):\n",
    "    model_name = \"topics_{}\".format(str(n_topics))\n",
    "    for a in a_list:\n",
    "        for b in b_list:\n",
    "            print(\"topics: {}, alpha: {}, beta: {}\".format(n_topics, a, b))\n",
    "            %time ldamodel = LdaMulticore(corpus, num_topics = n_topics, id2word=dictionary, passes=n_iterations, alpha=a, eta=b, workers=w)\n",
    "            topics = ldamodel.print_topics(num_words=NUM_WORDS)\n",
    "            perplexity = ldamodel.log_perplexity(corpus)\n",
    "            coherence_model = CoherenceModel(model=ldamodel, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "            coherence = coherence_model.get_coherence()\n",
    "            print(model_name)\n",
    "            print(best_models.keys())\n",
    "            if model_name not in best_models:\n",
    "                best_models[model_name] = {\"alpha\":a, \"beta\":b, \"coherence\":coherence}\n",
    "                ldamodel.save(path_tune_models.format(forum, group, str(n_topics)))\n",
    "            else:\n",
    "                print(best_models[model_name][\"coherence\"])\n",
    "                print(coherence)\n",
    "                if best_models[model_name][\"coherence\"] < coherence:\n",
    "                    print(\"new best model\")\n",
    "                    best_models[model_name] = {\"alpha\":a, \"beta\":b, \"coherence\":coherence}\n",
    "                    ldamodel.save(path_tune_models.format(forum, group, str(n_topics)))\n",
    "            for topic in topics:\n",
    "                write_list(path_a_b_t_tune.format(forum, group, search, run), [coherence, perplexity, n_topics, a, b, topic[0], topic[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 6s, sys: 2min 19s, total: 8min 25s\n",
      "Wall time: 7min 22s\n",
      "0.160*\"get\" + 0.027*\"one\" + 0.027*\"still\" + 0.024*\"therapy\" + 0.020*\"old\" + 0.019*\"do\" + 0.018*\"services\" + 0.016*\"test\" + 0.016*\"2\" + 0.012*\"ot\"\n",
      "0.198*\"kid\" + 0.097*\"dont\" + 0.096*\"think\" + 0.055*\"issue\" + 0.035*\"many\" + 0.033*\"well\" + 0.022*\"lot\" + 0.022*\"behavior\" + 0.018*\"problem\" + 0.015*\"understand\"\n",
      "0.080*\"say\" + 0.064*\"want\" + 0.050*\"he\" + 0.048*\"im\" + 0.035*\"doesnt\" + 0.028*\"cant\" + 0.026*\"something\" + 0.025*\"never\" + 0.023*\"always\" + 0.017*\"anything\"\n",
      "0.235*\"school\" + 0.102*\"dc\" + 0.075*\"sn\" + 0.032*\"class\" + 0.031*\"year\" + 0.026*\"private\" + 0.022*\"public\" + 0.018*\"move\" + 0.014*\"would\" + 0.011*\"option\"\n",
      "0.063*\"would\" + 0.057*\"op\" + 0.048*\"tell\" + 0.046*\"right\" + 0.039*\"thats\" + 0.036*\"may\" + 0.033*\"didnt\" + 0.033*\"call\" + 0.031*\"maybe\" + 0.030*\"thanks\"\n",
      "0.091*\"child\" + 0.035*\"support\" + 0.029*\"also\" + 0.028*\"program\" + 0.021*\"college\" + 0.021*\"go\" + 0.020*\"ld\" + 0.018*\"high\" + 0.016*\"student\" + 0.016*\"camp\"\n",
      "0.093*\"like\" + 0.031*\"friend\" + 0.023*\"love\" + 0.021*\"mom\" + 0.021*\"seem\" + 0.019*\"age\" + 0.018*\"thought\" + 0.016*\"etc\" + 0.015*\"little\" + 0.014*\"stuff\"\n",
      "0.070*\"yes\" + 0.042*\"give\" + 0.029*\"nyc\" + 0.020*\"pay\" + 0.019*\"district\" + 0.018*\"case\" + 0.015*\"doe\" + 0.012*\"live\" + 0.012*\"fund\" + 0.011*\"send\"\n",
      "0.094*\"ds\" + 0.069*\"help\" + 0.056*\"try\" + 0.052*\"work\" + 0.039*\"dd\" + 0.033*\"start\" + 0.013*\"read\" + 0.012*\"focus\" + 0.012*\"also\" + 0.012*\"well\"\n",
      "0.061*\"np\" + 0.060*\"adhd\" + 0.054*\"med\" + 0.033*\"anxiety\" + 0.026*\"different\" + 0.022*\"son\" + 0.021*\"asd\" + 0.021*\"change\" + 0.018*\"dx\" + 0.016*\"add\"\n",
      "0.054*\"time\" + 0.054*\"take\" + 0.051*\"go\" + 0.024*\"day\" + 0.018*\"back\" + 0.018*\"home\" + 0.017*\"dh\" + 0.015*\"week\" + 0.014*\"long\" + 0.013*\"let\"\n",
      "0.130*\"know\" + 0.067*\"good\" + 0.045*\"great\" + 0.043*\"people\" + 0.037*\"use\" + 0.031*\"us\" + 0.026*\"anyone\" + 0.020*\"experience\" + 0.020*\"hear\" + 0.020*\"someone\"\n",
      "0.077*\"really\" + 0.055*\"see\" + 0.046*\"much\" + 0.041*\"parent\" + 0.038*\"ask\" + 0.038*\"even\" + 0.037*\"could\" + 0.030*\"look\" + 0.027*\"getting\" + 0.019*\"isnt\"\n",
      "0.127*\"need\" + 0.048*\"teacher\" + 0.028*\"find\" + 0.026*\"iep\" + 0.026*\"first\" + 0.024*\"new\" + 0.023*\"therapist\" + 0.022*\"talk\" + 0.015*\"would\" + 0.015*\"come\"\n",
      "0.056*\"make\" + 0.043*\"going\" + 0.042*\"hard\" + 0.040*\"things\" + 0.032*\"one\" + 0.026*\"feel\" + 0.025*\"better\" + 0.022*\"mean\" + 0.021*\"family\" + 0.020*\"way\"\n"
     ]
    }
   ],
   "source": [
    "forum = 'special-needs'\n",
    "group = 'all'\n",
    "n_topics = 15\n",
    "a = 0.7\n",
    "b = 0.1\n",
    "NUM_WORDS = 10\n",
    "n_iterations = 50\n",
    "w = 15 # 16 cores (1 main + 15 workers)\n",
    "%time ldamodel = LdaMulticore(corpus, num_topics = n_topics, id2word=dictionary, passes=n_iterations, alpha=a, eta=b, workers=w)\n",
    "topics = ldamodel.print_topics(num_words=NUM_WORDS)\n",
    "coherence_model = CoherenceModel(model=ldamodel, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "for topic in topics:\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742621474732515\n"
     ]
    }
   ],
   "source": [
    "print(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.save(path_tune_models.format(forum, group, str(n_topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Dominant Topic in each Post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=corpus)\n",
    "df_topic_sents_keywords.info()\n",
    "df_topic_sents_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "path_db = str(path_parent / \"database\" / \"youbemom-merged.db\")\n",
    "sql = '''\n",
    "    SELECT s.text_no_url AS text_no_url, s.text as text\n",
    "    FROM sentiment AS s\n",
    "    JOIN posts AS p\n",
    "    ON s.message_id = p.message_id\n",
    "    WHERE p.subforum=\"special-needs\" AND p.parent_id=\"\"\n",
    "'''\n",
    "conn = create_connection(path_db)\n",
    "sn = pd.read_sql_query(sql, conn)\n",
    "sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Topics and Keywords in New Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(path_db)\n",
    "df_topic_sents_keywords.to_sql('topicmodel', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
