{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sentiment Analysis on Forum Data\n",
    "This notebook loads the Youbemom forum data and calculates sentiment\n",
    "\n",
    "## Data Sources\n",
    "- youbemom-merged.db (created with 1.1-Merge_Databases.ipynb)\n",
    "\n",
    "## Changes\n",
    "- 2020-08-13: Set up data cleaning\n",
    "- 2020-08-20: Added t-tests\n",
    "- 2020-08-26: Added plots\n",
    "- 2020-09-14: Added more plots\n",
    "- 2020-09-15: Compared parent and child sentiment\n",
    "- 2020-12-10: Changed data set\n",
    "- 2020-12-13: Moved data analysis to new file\n",
    "\n",
    "## Database Structure\n",
    "- threads\n",
    " - id: automatically assigned\n",
    " - url: url of top post\n",
    " - subforum: subforum of post\n",
    " - dne: post does not exist\n",
    "- posts\n",
    " - id: automatically assigned\n",
    " - family_id: thread->id\n",
    " - message_id: the unique id of the message from the html\n",
    " - parent_id: id of post this post is responding to, 0 if top post\n",
    " - date_recorded: date the data is fetched\n",
    " - date_created: date the data was created\n",
    " - title: title of the post\n",
    " - body: body of the post\n",
    " - subforum: subforum of post\n",
    " - deleted: has post been deleted\n",
    "\n",
    "## TODO\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from youbemom import create_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "For formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    \"\"\" format the data frame from sql so dates are in\n",
    "        datetime format and creates text column from\n",
    "        title and body\n",
    "    :param df: data frame\n",
    "    :return df: formatted data frame\n",
    "    \"\"\"\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "    df['date_created'] = pd.to_datetime(df['date_created'])\n",
    "    # text = title + body\n",
    "    df['title'] = df['title'].replace('This post has been deleted\\.', '', regex=True)\n",
    "    df['text'] = df['title'] + \" \" + df['body']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     \"\"\" cleans the input text of punctuation, extra\n",
    "#         spaces, and makes letters lower case\n",
    "#     :param text: text (= title + body here)\n",
    "#     :return clean: clean text\n",
    "#     \"\"\"\n",
    "#     clean = \"\".join([t for t in text if t not in string.punctuation])\n",
    "#     clean = re.sub(\" +\", \" \", clean)\n",
    "#     clean = clean.strip()\n",
    "#     clean = clean.lower()\n",
    "#     return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords(text):\n",
    "#     \"\"\" remove all stop words from the text\n",
    "#         using stopwords from nltk.corpus\n",
    "#     :param text: text with stopwords\n",
    "#     :return words: text without stopwords\n",
    "#     \"\"\"\n",
    "#     words = [w for w in text if w not in stopwords.words('english')]\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating the sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence, analyzer):\n",
    "    \"\"\" create sentiment scores with the VADER analyzer\n",
    "    :param sentence: sentence to create scores for\n",
    "    :param analyzer: VADER sentiment analyzer\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_db = path_parent / \"database\" / \"youbemom-merged.db\"\n",
    "path_db = str(path_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(path_db)\n",
    "df = pd.read_sql_query(\"SELECT * from posts\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data\n",
    "Format the data to make dates into datetimes and create a text column from the title and body. Also, filter the data to include only dates starting Jan. 1, 2019. The scraper picked up one post from 2015 so this removes that. I want to see if there is a difference between parent and child posts so I made an \"is_parent\" indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16696050 entries, 0 to 16696049\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   id             int64 \n",
      " 1   family_id      int64 \n",
      " 2   message_id     object\n",
      " 3   parent_id      object\n",
      " 4   date_recorded  object\n",
      " 5   date_created   object\n",
      " 6   title          object\n",
      " 7   body           object\n",
      " 8   subforum       object\n",
      " 9   deleted        int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = format_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['date_created']>pd.Timestamp(2019,1,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['before'] = df['date_created'] <= pd.Timestamp(2020,2,28)\n",
    "df['during'] = df['date_created'] >= pd.Timestamp(2020,4,1)\n",
    "df['march'] = ~df['before'] & ~df['during']\n",
    "df.loc[df['before'], 'period'] = 'before'\n",
    "df.loc[df['march'], 'period'] = 'march'\n",
    "df.loc[df['during'], 'period'] = 'during'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_parent'] = df['parent_id'] == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['date_created'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_n'] = df['date_created'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday_n'] = df['date_created'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date_created'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_n'] = df['date_created'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the text as collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = df['text'].apply(lambda x: sentiment_analyzer_scores(x, analyzer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg_sentiment'] = sentiment.apply(lambda x: x.get('neg', 0))\n",
    "df['neu_sentiment'] = sentiment.apply(lambda x: x.get('neu', 0))\n",
    "df['pos_sentiment'] = sentiment.apply(lambda x: x.get('pos', 0))\n",
    "df['compound_sentiment'] = sentiment.apply(lambda x: x.get('compound', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.747, 'pos': 0.253, 'compound': 0.5267}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also do this without stop words or punctuation but VADER includes puctuation in sentiment calculation. \"!\", ALLCAPS, and degree modifiers (like \"extremely\" or \"marginally\") affects the magnitude of a sentiment. Conjunctions like \"but\" can flip the sentiment polarity. Below, we can see that the shift in sentiment is the same whether or not we include stop words, pucntuation, and lowercase everything but I'll use the as-collected text instead of the clean text in the rest of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('posts', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
