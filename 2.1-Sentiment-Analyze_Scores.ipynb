{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Sentiment for Forum Data\n",
    "This notebook loads the sentiment data and explores results\n",
    "\n",
    "## Data Sources\n",
    "- youbemom-merged.db (with sentiment scores from 2.0-Sentiment-Create_Scores.ipynb)\n",
    "\n",
    "## Changes\n",
    "- 2020-12-13: Created\n",
    "- 2020-01-07: Seasonality\n",
    "\n",
    "## Database Structure\n",
    "- threads\n",
    " - id: automatically assigned\n",
    " - url: url of top post\n",
    " - subforum: subforum of post\n",
    " - dne: post does not exist\n",
    "- posts\n",
    " - id: automatically assigned\n",
    " - family_id: thread->id\n",
    " - message_id: the unique id of the message from the html\n",
    " - parent_id: id of post this post is responding to, 0 if top post\n",
    " - date_recorded: date the data is fetched\n",
    " - date_created: date the data was created\n",
    " - title: title of the post\n",
    " - body: body of the post\n",
    " - subforum: subforum of post\n",
    " - deleted: has post been deleted\n",
    "- sentiment\n",
    " - message_id: message id connecting to posts\n",
    " - text: title + body\n",
    " - text_no_url: text without urls\n",
    " - neg_sen_all\n",
    " - neu_sen_all\n",
    " - pos_sen_all\n",
    " - com_sen_all\n",
    " - neg_sen_no_url\n",
    " - neu_sen_no_url\n",
    " - pos_sen_no_url\n",
    " - com_sen_no_url\n",
    "\n",
    "## TODO\n",
    "- Does python have a regression function for continuous dependent variables between 0 and 1 or will I have to use R/Stata for a fractional regression model?\n",
    "- Set up functions for the plots so I can plug in the variable I want to see\n",
    "- Does sentiment differ between parents and children in threads?\n",
    " - Is sentiment more negative after negative posts? More positive after positive posts?\n",
    "- Is there a time-dependent function here?\n",
    " - Seasonality?\n",
    " - Does tweaking the time period cutoffs affect the significance?\n",
    "- Frequency distribution of words\n",
    "- Robustness checks of different samples\n",
    "- Scrape the rest of December so frequency counts are right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy.stats import ttest_ind, kde\n",
    "from datetime import datetime\n",
    "# from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer #, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statsmodels.formula.api  import ols\n",
    "from youbemom import create_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_sentiment(df, v):\n",
    "    \"\"\" run a t-test on the sentiment scores for\n",
    "        before and during the pandemic\n",
    "    :param df: data frame\n",
    "    :param v: the variable name to t-test on\n",
    "    :return: nothing, prints ttest results\n",
    "    \"\"\"\n",
    "    group_before = df.where(df['before'])[v].dropna()\n",
    "    group_during = df.where(df['during'])[v].dropna()\n",
    "    result = ttest_ind(group_before, group_during, equal_var=False, nan_policy=\"omit\")\n",
    "    print('\\n')\n",
    "    l = len(v)\n",
    "    print(' '*(l - 8) + 'variable    before    during statistic    pvalue')\n",
    "    print(v + '  {:1.6f}  {:1.6f} {:+1.6f}  {:1.6f}'.format(group_before.mean(), group_during.mean(), result.statistic, result.pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dates(df):\n",
    "    \"\"\" create date variables\n",
    "    :param df: data frame\n",
    "    :return: formatted data frame\n",
    "    \"\"\"\n",
    "    df['date_created'] = pd.to_datetime(df['date_created'])\n",
    "    df['before'] = df['date_created'] <= pd.Timestamp(2020,2,28)\n",
    "    df['during'] = df['date_created'] >= pd.Timestamp(2020,4,1)\n",
    "    df['march'] = ~df['before'] & ~df['during']\n",
    "    df.loc[df['before'], 'period'] = 'before'\n",
    "    df.loc[df['march'], 'period'] = 'march'\n",
    "    df.loc[df['during'], 'period'] = 'during'\n",
    "    df['weekday'] = df['date_created'].dt.day_name()\n",
    "    df['week_n'] = df['date_created'].dt.isocalendar().week\n",
    "    df['weekday_n'] = df['date_created'].dt.day\n",
    "    df['month'] = df['date_created'].dt.month_name()\n",
    "    df['month_n'] = df['date_created'].dt.month\n",
    "#     df['ymd'] = df['date_created'].dt.to_period('D')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_parent_child(df):\n",
    "    parents = df[df[\"is_parent\"]]\n",
    "    parents = parents[[\"family_id\",\"neg_sentiment\",\"pos_sentiment\",\"compound_sentiment\"]]\n",
    "    children = df[~df[\"is_parent\"]]\n",
    "    children = children[[\"family_id\",\"neg_sentiment\",\"pos_sentiment\",\"compound_sentiment\"]]\n",
    "    children_ave = children.groupby(\"family_id\", as_index=False).mean()\n",
    "    compare = pd.merge(left=parents, right=children_ave, on=\"family_id\", how=\"inner\", suffixes=['_p','_c'])\n",
    "    compare['pos_diff'] = compare['pos_sentiment_p'] - compare['pos_sentiment_c']\n",
    "    compare['neg_diff'] = compare['neg_sentiment_p'] - compare['neg_sentiment_c']\n",
    "    compare['compound_diff'] = compare['compound_sentiment_p'] - compare['compound_sentiment_c']\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_sentiment(df, name, var):\n",
    "    grouping_ave = df.groupby([var])['compound_sentiment'].mean()\n",
    "    path_sen = path_parent / \"clean_data\" / \"sentiment_{0}_{1}.csv\".format(name, var)\n",
    "    path_sen = str(path_sen)\n",
    "    grouping_ave.to_csv(path_sen)\n",
    "    print(grouping_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_freq(df, name, var):\n",
    "    grouping_freq = df.groupby(var)[var].count()\n",
    "    path_freq = path_parent / \"clean_data\" / \"frequency_{0}_{1}.csv\".format(name, var)\n",
    "    path_freq = str(path_freq)\n",
    "    grouping_freq.to_csv(path_freq)\n",
    "    print(grouping_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ave_sent_day(df):\n",
    "    daily_ave = df[['date_created','compound_sentiment']].copy()\n",
    "    daily_ave = daily_ave.set_index('date_created')\n",
    "    daily_ave = daily_ave.resample('D').mean().dropna(how='all')\n",
    "    daily_ave['period'] = \"March\"\n",
    "    daily_ave.loc[daily_ave.index <= pd.Timestamp(2020,2,28), 'period'] = \"Before\"\n",
    "    daily_ave.loc[daily_ave.index >= pd.Timestamp(2020,4,1), 'period'] = \"During\"\n",
    "    return daily_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_freq(df):\n",
    "    freq = df[['date_created', 'compound_sentiment']].copy()\n",
    "    freq = freq.set_index('date_created')\n",
    "    freq = freq.resample('D').size().dropna(how='all').to_frame()\n",
    "    freq.columns = ['daily_count']\n",
    "    freq['period'] = \"March\"\n",
    "    freq.loc[freq.index <= pd.Timestamp(2020,2,28), 'period'] = \"Before\"\n",
    "    freq.loc[freq.index >= pd.Timestamp(2020,4,1), 'period'] = \"During\"\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dates(df, start, end):\n",
    "    mask = (df['date_created'] >= start) & (df['date_created'] < end)\n",
    "    return df.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_db = path_parent / \"database\" / \"youbemom-merged.db\"\n",
    "path_db = str(path_db)\n",
    "path_counts = path_parent / \"clean_data\" / \"subforum-counts.csv\"\n",
    "path_counts = str(path_counts)\n",
    "path_sn = path_parent / \"clean_data\" / \"sn_sentiment.csv\"\n",
    "path_td = path_parent / \"clean_data\" / \"td_sentiment.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts of posts in each subforum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_sql = '''\n",
    "    SELECT subforum, COUNT(family_id), MIN(date_created), MAX(date_created)\n",
    "    FROM posts\n",
    "    GROUP BY subforum\n",
    "'''\n",
    "counts = pd.read_sql_query(counts_sql, conn)\n",
    "counts.to_csv(path_counts, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special needs subforum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts: message_id (merge var), date_created, parent_id\n",
    "# sentiment: message_id (merge var), *_sen_* (sentiment variables)\n",
    "sn_sql = '''\n",
    "    SELECT\n",
    "        p.message_id AS message_id,\n",
    "        p.date_created AS date_created,\n",
    "        p.parent_id AS parent_id,\n",
    "        s.neg_sen_all as neg_sen_all,\n",
    "        s.neu_sen_all as neu_sen_all,\n",
    "        s.pos_sen_all as pos_sen_all,\n",
    "        s.com_sen_all as com_sen_all,\n",
    "        s.neg_sen_no_url as neg_sen_no_url,\n",
    "        s.neu_sen_no_url as neu_sen_no_url,\n",
    "        s.pos_sen_no_url as pos_sen_no_url,\n",
    "        s.com_sen_no_url as com_sen_no_url\n",
    "    FROM posts AS p\n",
    "    JOIN sentiment AS s\n",
    "    ON p.message_id = s.message_id\n",
    "    WHERE p.subforum = \"special-needs\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = pd.read_sql_query(sn_sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = create_dates(sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.to_csv(path_sn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toddler subforum: generate a 10% sample of family_ids to make processing easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ids_sql = ''' SELECT family_id FROM threads WHERE subforum=\"toddler\" '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ids = pd.read_sql_query(td_ids_sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_10per_sample = td_ids.sample(frac = 0.1, random_state = 281)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_10per_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table_sql = ''' \n",
    "    CREATE TEMPORARY TABLE\n",
    "        temp(id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE, family_id INTEGER);\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(temp_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_10per_sample.to_sql('temp', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts: message_id (merge var), date_created, parent_id\n",
    "# sentiment: message_id (merge var), *_sen_* (sentiment variables)\n",
    "td_sql = '''\n",
    "    SELECT\n",
    "        p.message_id AS message_id,\n",
    "        p.date_created AS date_created,\n",
    "        p.parent_id AS parent_id,\n",
    "        s.neg_sen_all as neg_sen_all,\n",
    "        s.neu_sen_all as neu_sen_all,\n",
    "        s.pos_sen_all as pos_sen_all,\n",
    "        s.com_sen_all as com_sen_all,\n",
    "        s.neg_sen_no_url as neg_sen_no_url,\n",
    "        s.neu_sen_no_url as neu_sen_no_url,\n",
    "        s.pos_sen_no_url as pos_sen_no_url,\n",
    "        s.com_sen_no_url as com_sen_no_url\n",
    "    FROM posts AS p\n",
    "    JOIN sentiment AS s\n",
    "    ON p.message_id = s.message_id\n",
    "    WHERE p.family_id IN (SELECT family_id FROM temp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_sql_query(td_sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop temp table\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = create_dates(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(path_td, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subsets in correct date range: 2018-01-01 to 2020-11-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_sub = filter_dates(td, pd.Timestamp(2014, 1, 1, 0, 0, 0), pd.Timestamp(2020, 12, 1, 0, 0, 0))\n",
    "sn_sub = filter_dates(sn, pd.Timestamp(2014, 1, 1, 0, 0, 0), pd.Timestamp(2020, 12, 1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comparing sentiment before and during pandemic with a t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, df in {\"Special Needs\":sn_sub, \"Toddler\":td_sub}.items():\n",
    "    print(name)\n",
    "    ttest_sentiment(df, 'neg_sen_no_url')\n",
    "    ttest_sentiment(df, 'neu_sen_no_url')\n",
    "    ttest_sentiment(df, 'pos_sen_no_url')\n",
    "    ttest_sentiment(df, 'com_sen_no_url')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in {\"Special Needs\":sn_sub, \"Toddler\":td_sub}.items():\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.35\n",
    "    sentiments = ['Negative', 'Positive']\n",
    "    x_pos = np.arange(len(sentiments))\n",
    "\n",
    "    before_mean = [df[\"neg_sentiment\"][df['before']].mean(),\n",
    "                   df[\"pos_sentiment\"][df['before']].mean()]\n",
    "    before_se = [df[\"neg_sentiment\"][df['before']].std()/math.sqrt(len(df[\"neg_sentiment\"][df['before']])),\n",
    "                 df[\"pos_sentiment\"][df['before']].std()/math.sqrt(len(df[\"pos_sentiment\"][df['before']]))]\n",
    "    during_mean = [df[\"neg_sentiment\"][df['during']].mean(),\n",
    "                   df[\"pos_sentiment\"][df['during']].mean()]\n",
    "    during_se = [df[\"neg_sentiment\"][df['during']].std()/math.sqrt(len(df[\"neg_sentiment\"][df['during']])),\n",
    "                 df[\"pos_sentiment\"][df['during']].std()/math.sqrt(len(df[\"pos_sentiment\"][df['during']]))]\n",
    "\n",
    "    rects_before = ax.bar(x_pos - width/2, before_mean, width, yerr=before_se,\n",
    "                    label='Before', capsize=5, color=\"cornflowerblue\")\n",
    "    rects_during = ax.bar(x_pos + width/2, during_mean, width, yerr=during_se,\n",
    "                    label='During', capsize=5, color=\"indianred\")\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Average Sentiment Score\\n(normalized 0 to 1)')\n",
    "    ax.set_title('Comparison of Sentiment Scores: {}'.format(name))\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(sentiments)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "#     plt.savefig('../plots/sentiment_neg_pos.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparing sentiment of parent and child posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df in [sn_sub, td_sub]:\n",
    "    print(\"\\nGROUP\\n\")\n",
    "    compare = compare_parent_child(df)\n",
    "    est_pos = ols(formula = 'pos_sentiment_c ~ pos_sentiment_p', data = compare).fit()\n",
    "    print(est_pos.summary())\n",
    "    est_neg = ols(formula = 'neg_sentiment_c ~ neg_sentiment_p', data = compare).fit()\n",
    "    print(est_neg.summary())\n",
    "    est_compound = ols(formula = 'compound_sentiment_c ~ compound_sentiment_p', data = compare).fit()\n",
    "    print(est_compound.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this suggests if a parent comment's negative sentiment increases, the children's negative sentiment will increase as well. Perhaps redo this analysis on each observation rather than the average children's sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare density of compound sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, df in {\"Special Needs\":sn_sub, \"Toddler\":td_sub}.items():\n",
    "    density_before = kde.gaussian_kde(df[\"compound_sentiment\"][df['before']])\n",
    "    density_march = kde.gaussian_kde(df[\"compound_sentiment\"][df['march']])\n",
    "    density_during = kde.gaussian_kde(df[\"compound_sentiment\"][df['during']])\n",
    "    x = np.arange(-1.0, 1.0, 0.01)\n",
    "    plt.scatter(x, density_before(x), alpha=0.5, label=\"Before\")\n",
    "    plt.scatter(x, density_march(x), alpha=0.5, label=\"March\")\n",
    "    plt.scatter(x, density_during(x), alpha=0.5, label=\"During\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('Density of Compound Sentiment Scores: {}'.format(name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3\n",
    "for name, df in {\"Special Needs\":sn, \"Toddler\":td_sub}.items():\n",
    "    daily_ave = ave_sent_day(df)\n",
    "    groups = daily_ave.groupby('period')\n",
    "    for period, group in groups:\n",
    "        plt.scatter(group.index, group.compound_sentiment, label=period, s=size)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Compound Sentiment\\n(normalized -1 to 1)')\n",
    "    plt.title('Daily Average Compound Sentiment Scores: {}'.format(name))\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compare post frequency over same period for special needs and toddler subforums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3\n",
    "for name, df in {\"Special Needs\":sn, \"Toddler\":td_sub}.items():\n",
    "    freq = daily_freq(df)\n",
    "    groups = freq.groupby('period')\n",
    "    for period, group in groups:\n",
    "        plt.scatter(group.index, group.daily_count, label=period, s=size)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Daily Frequency of Posts: {}'.format(name))\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
